## [П]|[РС]|(РП) Оптические потоки

Ранее уже было сказано, что иногда может возникнуть необходимость в оценке движений между двумя кадрами (или последовательностью кадров) без каких-либо других предварительно полученных знаний о содержании этих кадров. Как правило, само движение является знаком того, что происходит что-то интересное. Оптический поток представлен на рисунке 10-3.

![Рисунок 10-3 не найден](Images/Pic_10_3.jpg)

Рисунок 10-3. Оптический поток: целевые особенности (сверху слева) отслеживаются в течение долгого времени, а их движения преобразуются в вектор скорости (сверху справа); в нижней части рисунку представлено общий вид коридора (слева) и вектор потока (справа) того, как движется камера по коридору

Можно связать некую скорость каждого пикселя в кадре или, что эквивалентно, некоторое смещение, представляющее собой расстояние на которое сместится пиксель при сравнении предыдущего и текущего кадра. Такая конструкция обычно именуется *плотным оптическим потоком*, который связывает скорость с каждым пикселем изображения. *Метод Horn-Schunck* пытается вычислять только скорости полей. Еще один, казалось бы, простой метод – просто пытающийся сопоставить окна вокруг каждого пикселя от кадра к кадру – так же реализован в OpenCV; этот метод известен как *метод блочного сопоставления*. Оба представленных метода будут более детально представлены в разделе "Методы плотного слежения".

На практике рассчитать плотный оптический поток не так то и легко. Рассмотрим пример движения белого листа бумаги. Многие белые пиксели из предыдущего кадра остаются белыми и в последующем кадре. При этом изменениям могут быть подвержены лишь края и то только те, что перпендикулярны направлению движения. Как результат, плотные методы должны иметь в наличии некоторые методы интерполяции между точками, которые легче отследить, для вычисления неоднозначных точек. Эти проблемы наиболее ярко проявляются в виде высоких вычислительных затратах плотного оптического потока.

Это порождает альтернативный вариант, *разряженный оптический поток*. Алгоритмы такого рода опираются на заранее заданное некоторым образом подмножество точек, которое подлежит отслеживанию. Если точки обладают заранее определенными подходящими свойствами, такими как ранее обсуждаемые "углы", то отслеживание будет относительно прочным и надежным. OpenCV может помочь при решении данного вопроса, путем предоставления процедур для выявления лучших особенностей для отслеживания. На практике вычислительная стоимость от использования разряженного потока намного меньше, чем от использования плотного потока, поэтому интерес к последнему лишь академический. (Black и Anadan создали методы плотного оптического потока, которые зачастую используются при создании фильмов, в которых упор делается на получение качественной картинки. Эти методы планируется включить в более поздние версии OpenCV, глава 14).

В следующих разделах будет представлено несколько различных методов отслеживания. Вначале будет представлена наиболее популярная разряженная техника слежения, оптический поток Lucas-Kanade (LK); этот метод также имеет вариант реализации для работы с пирамидой изображений, позволяющий отслеживать быстрые движения. Затем будут представлены две плотные техники слежения, метод Horn-Schunck и метод сопоставления блоков.


### Метод Lucas-Kanade

Первоначально предполагалось (в 1981 году), что алгоритм Lucas-Kanade (LK) будет использоваться для создания плотных потоков. Но, т.к. метод легко применить к подмножеству точек исходного изображения, он стал более важен для создания разряженных потоков. Алгоритм LK может быть применен в контексте разряженного потока, т.к. опирается только на локальную информацию, которая является производной от некоторого небольшого окна, окружающее каждую, вызывающую интерес, точку. Это главное отличие от алгоритма Horn и Schunck, где используются глобальные характеристики (подробнее об этом позже). Недостаток использования небольших локальных окон в методе Lukas-Kanade заключается в том, что большие сдвиги могут переместить точки за пределы локального окна, в результате чего невозможно будет осуществить поиск. Эта проблема привела к появлению "пирамидального" алгоритма LK, который начинает отслеживать от наивысшего (с низкой детализацией) к более низшему (с высокой детализацией) уровню пирамиды. Слежение при помощи пирамид позволяет поймать большие перемещения в пределах локального окна. 

Т.к. это важный и эффективный метод, то вначале будут представлены математические детали; читатели, которым данные детали не интересны, могут сразу перейти к описанию функций и разбору кода. Однако, рекомендуется все же изучить эти детали хотя бы для того, чтобы интуитивно понимать, что делать, если отслеживание работает плохо.

**Принципы работы алгоритма Lucas-Kanade**

Основная идея алгоритма LK заключена в трех предположениях.

1. *Постоянство яркости*. Пиксель объекта на изображении не изменяется внешне (по возможности) при перемещении от кадра к кадру. Для серого изображения (LK так же можно применять и для цветного изображения) это предположение означает, что яркость пикселя не изменяется при слежении от кадра к кадру.

2. *Временное постоянство или "малые перемещения"*. Изменение движущейся поверхности патча изображения во времени происходит очень медленно. На практике это означает, что приращение времени достаточно велико относительно масштаба движения в изображении, то есть объект мало перемещаем от кадра к кадру.

3. *Пространственная когерентность*. Соседние точки на сцене, принадлежащие одной поверхности, имеют аналогичные движения и проектируются к соседним точкам на плоскости изображения.

Представленные предположения, проиллюстрированные на рисунке 10-4, дают эффективный алгоритм слежения. Первое требование, постоянство яркости, является требованием, которое свидетельствует о том, что пиксели в одном отслеживаемом патче должны выглядеть одинаково в течение долгого времени:

![Формула 10-5 не найдена](Images/Frml_10_5.jpg)

![Рисунок 10-4 не найден](Images/Pic_10_4.jpg)

Рисунок 10-4. Предположения, составляющие основу оптического потока Lucas-Kanade: яркость патча, с отслеживаемым объектом в сцене, не меняется (сверху); перемещения медленны относительно частоты кадров (снизу слева); соседние точки остаются соседними (снизу справа)

Первое предположение достаточно простое и означает лишь то, что отслеживаемая интенсивность пикселя не изменяется в течение долгого времени:

![Формула 10-6 не найдена](Images/Frml_10_6.jpg)

Второе предположение, временное постоянство, по существу означает, что движения малы от кадра к кадру. Другими словами, можно рассматривать эти изменения как аппроксимацию производной интенсивности по времени (т.е. изменения между текущим и следующим кадрами малы). Для понимания данного предположения, рассмотрим случай с участием одной пространственной размерности.

В этом случае, все начинается с уравнения постоянства яркости с заменой яркости f(x, t) (принимая во внимание неявную зависимость x от t) на I(x(t), t) и последующим применением правила частичного дифференцирования. Все это даёт: 

![Формула 10-7 не найдена](Images/Frml_10_7.jpg)

где ![Формула 10-20 не найдена](Images/Frml_10_20.jpg) пространственная производная первого изображения, ![Формула 10-21 не найдена](Images/Frml_10_21.jpg) производная между изображениями на определенном промежутке времени и **v** скорость, которую необходимо найти. В результате получаем простое уравнение скорости оптического потока в простом одномерном случае:

![Формула 10-8 не найдена](Images/Frml_10_8.jpg)

Для начала необходимо разобраться с некоторыми интуитивными вещами одномерной задачи слежения. На рисунок 10-5 изображен "край" - состоящий из большого значения слева и малого значения справа - движущиеся вправо вдоль оси x. Цель заключается в том, чтобы определить скорость **v** с которой перемещается край, что собственно и изображено в верхней части рисунка 10-5. В нижней части рисунка показано, что измерение этой скорости — это просто "прирост движения", где прирост — это время, а движение — это наклон (пространственная производная). Отрицательный знак корректирует наклон относительно x.

Рисунок 10-5 показывает еще один аспект формулировки оптического потока: ранее изложенные предположения, вероятно, не совсем верны. Т.е. яркость изображения не очень стабильна, а временные шаги (которые устанавливаются при помощи камеры) зачастую не столь быстры относительно движения, как хотелось бы. В результате получаемая скорость не точна. Тем не менее, если быть "достаточно близкими", то можно справиться с проблемой итерационно. Итерация, показанная на рисунке 10-6, использует первоначальную (неточную) оценку скорости как отправную точку для последующих неоднократно повторяющихся итераций. Можно сохранить ту же пространственную производную по оси x, вычисленную в первом кадре, за счет предположения постоянства яркости – как результат, перемещение пикселей по оси x неизменно. Повторное использование уже вычисленной пространственной производной дает значительную вычислительную экономию. При этом производная по времени должна повторно вычисляться для каждой итерации и каждого кадра, однако, если быть достаточно близкими к началу, то сходимость (почти точная) достигается в пять итераций. Данный подход более известен как *метод Ньютона*. Если первая оценка не была достаточно близка, то метод Ньютона будет давать неверный ответ.

![Рисунок 10-5 не найден](Images/Pic_10_5.jpg)

Рисунок 10-5. Оптический поток Lucas-Kanade для одного измерения: можно оценить скорость движущегося края (сверху) путем измерения отношения производной по времени к производной пространственной интенсивности

![Рисунок 10-6 не найден](Images/Pic_10_6.jpg)

Рисунок 10-6. Итерационное уточнение решения оптического потока (метод Ньютона): используя два изображения и одну и ту же пространственную производную (наклон) для них, ищется производная по времени; сходимость к устойчивому решению, как правило, происходит по истечению нескольких итераций

Рассмотрев решение для одного измерения, можно перейти к рассмотрению случая с двумя измерениями. На первый взгляд может показаться, что все просто: всего то нужно добавить координату y. Небольшие изменения в обозначении и связывание компоненты y со скоростью v и компоненты x со скоростью u, получаем следующее уравнение:

![Формула 10-9 не найдена](Images/Frml_10_9.jpg)

К сожалению, это уравнение с двумя неизвестными для любого пикселя. Это означает, что использование измерений на уровне одного пикселя является недостаточным условием и потому не позволяет получить уникальное решение двумерного движения точки. В таком случае, решение возможно получить только для движущейся компоненты, которая перпендикулярна или "нормальна" к линии, описанная уравнением потока. На рисунке 10-7 представлены математические и геометрические детали.

![Рисунок 10-7 не найден](Images/Pic_10_7.jpg)

Рисунок 10-7. Двумерный оптический поток одного пикселя: оптический поток одного пикселя не определён и может привести к большему перемещению, которое перпендикулярно ("нормально") к линии, описанная уравнением потока

Полученные результаты нормального оптического потока – это последствия *проблемы отверстия*, возникающей от использования небольшого отверстия или окна, в котором производятся измерения движения. Чаще всего при слежении за движениями в малом отверстии можно увидеть только края, а не углы. Однако наличие только края является недостаточным условием для точного определения того, как (т.е. в каком направлении) перемещается весь объект, рисунок 10-8.

И все же, как обойти проблему, при которой по одному пикселю невозможно определить всё перемещение? Для решения проблемы необходимо обратиться к последнему предположению. Если локальный патч пикселей перемещается когерентно, то вполне легко можно рассчитать движение центрального пикселя при помощи окружающих пикселей, составив систему уравнений. Например, при использовании окна 5×5 (конечно окно может быть и 3×3 и 7×7 или еще каким-либо; если размер окна слишком большой, то это может привести к нарушению когерентности; если окно будет слишком маленьким, то вновь возникнет проблема отверстия) со значениями яркости (а можно и утроить для основного цветного оптического потока) текущего пикселя для вычисления его движения, то можно составить 25 уравнений следующего вида:

![Формула 10-10 не найдена](Images/Frml_10_10.jpg)

![Рисунок 10-8 не найден](Images/Pic_10_8.jpg)

Рисунок 10-8. Проблема отверстия: через отверстие окна (верхний ряд) можно отследить движения края вправо, однако движения вниз отследить не возможно (нижний ряд)

Теперь для имеющейся ограниченной системы можно найти решение, если окно 5×5 будет содержать нечто большее, чем просто край. Для решения данной системы необходимо провести исследование минимума методом наименьших квадратов, решив ![Формула 10-11 не найдена](Images/Frml_10_11.jpg) в стандартной форме:

![Формула 10-12 не найдена](Images/Frml_10_12.jpg)

Из этого соотношения можно получить компоненты движения v и u. Вот более подробное представление данного соотношения:

![Формула 10-13 не найдена](Images/Frml_10_13.jpg)

Решение данного уравнения выглядит следующим образом:

![Формула 10-14 не найдена](Images/Frml_10_14.jpg)

При каких условиях можно найти решение? – когда ![Формула 10-15 не найдена](Images/Frml_10_15.jpg) обратимо. А ![Формула 10-15 не найдена](Images/Frml_10_15.jpg) обратимо, когда имеет полный ранг матрицы (2), что осуществимо при наличии двух больших собственных векторов. Это справедливо для областей изображения, в которых есть текстуры, использующиеся как минимум в двух направлениях. В этом случае ![Формула 10-15 не найдена](Images/Frml_10_15.jpg) будет иметь хорошие свойства тогда, когда окно слежения будет центрироваться в угловой области изображения. В данном случае вспоминается ранее обсуждаемый угловой детектор Harris. На самом деле, эти углы являются "хорошими особенностями для отслеживания" (см. ранее рассмотренные замечания, касающиеся *cvGoodFeaturesToTrack()*) именно потому, что ![Формула 10-15 не найдена](Images/Frml_10_15.jpg) обладает двумя большими собственными векторами! Чуть позже будет показано, что все эти вычисления можно произвести при помощи функции *cvCalcOpticalFlowLK()*.

Читатели, которые понимают последствия предположения о малых и когерентных движениях могут быть обеспокоены тем фактом, что для большинства камер, работающих с частотой 30 Гц, наличие больших и некогерентных движений является обычным явлением. На самом деле оптический поток Lukas-Kanade сам по себе не очень хорошо работает именно по этой причине: стремление использовать большое окно для отслеживания большей составляющей движений слишком часто нарушает предположение о когерентности движения! Чтобы обойти эту проблему, можно сначала произвести слежение в больших пространственных масштабах, используя пирамиду изображения, а затем улучшать найденную начальную скорость движения, двигаясь вниз по уровням пирамиды пока не будут достигнуты необработанные пиксели изображения.

Следовательно, рекомендуемый метод вначале найдет решение для оптического потока в верхнем слое, а затем использует полученные оценки движения в качестве отправной точки в последующем нижележащем слое. Спуск по пирамиде осуществляется таким образом до тех пор, пока не будет достигнут последний слой. Таким образом, нарушения предположений сводятся к минимуму, и потому отслеживание движений осуществляется быстрее и продолжительнее. Эта более сложная функция известна как *пирамидальный оптический поток Lucas-Kanade*, рисунок 10-9. Функция *cvCalcOpticalFlowPyrLK()* реализует пирамидальный оптический поток Lucas-Kanade.

**Не пирамидальный оптический поток Lucas-Kanade**

Функция, реализующая алгоритм не пирамидального плотного оптического потока Lucas-Kanade:

```cpp
void cvCalcOpticalFlowLK(
     const CvArr*   imgA
    ,const CvArr*   imgB
    ,CvSize         winSize
    ,CvArr*         velx
    ,CvArr*         vely
);
```

Результирующие массивы этой функции будут заполнены только теми пикселями, для которых возможно вычислить минимальную ошибку. Для пикселей, у которых не может быть вычислена эта ошибка (и таким образом смещение), связанная с ними скорость будет установлена в 0. В большинстве случаев, данная функция не используется. Следующий метод, основанный на пирамиде, в большинстве случаев дает намного лучшие результаты.

**Пирамидальный оптический поток Lucas-Kanade**

Функция *cvCalcOpticalFlowPyrLK()* используется для реализации алгоритма пирамидального оптического потока Lucas-Kanade. Как будет показано далее, данная функция использует "хорошие особенности для отслеживания", а также возвращает показания того, насколько хорошо происходит слежение. 

```cpp
void cvCalcOpticalFlowPyrLK(
     const CvArr*   imgA
    ,const CvArr*   imgB
    ,CvArr*         pyrA
    ,CvArr*         pyrB
    ,CvPoint2D32f*  featuresA
    ,CvPoint2D32f*  featuresB
    ,int            count
    ,CvSize         winSize
    ,int            level
    ,char*          status
    ,float*         track_error
    ,CvTermCriteria criteria
    ,int            flags
);
```

Эта функция имеет большой набор входных параметров. Первых два аргумента – это исходное и конечное изображения; оба одноканальные, 8-битные изображения. Следующие два аргумента это буферы, выделяемые под хранение пирамиды изображений. Размер этих буферов должен быть не менее *(img.width + 8)×img.height/3* байт (размер выбран таким потому что в этих scratch пространства необходимо разместить не только изображение, но и пирамиду), по одному для каждого исходного изображения (*pyrA* и *pyrB*). (Если эти два указателя установлены в NULL, то выделение, использование и освобождение памяти будет происходить при вызове функции, что сказывается на производительности.) Массив *featuresA* содержит перемещающиеся точки, которые необходимо найти, *featuresB* - это аналогичный массив, в котором размещаются новые вычисленные локации точек массива *featursA*; *count* - это количество точек в списке *featuresA*. Параметр *winSize* задает окно, используемое для вычисления локально когерентного перемещения. В связи с эти происходит построение пирамиды изображения для которой аргумент *level* задает глубину стека изображений. Если level установлен в 0, то пирамида не используется. Массив *status* имеет размерность *count*; в результате выполнения функции, этот массив будет содержать либо 1 (если соответствующая точка была найдена на втором изображении), либо 0 (если не найдена). Параметр *track_error* необязателен и может быть выключен путем установки в NULL. Если все же параметр *track_error* используется, то это массив чисел, по одному числу для каждой отслеживаемой точки и равное разнице между патчем отслеживаемой точки на первом изображении и патчем с места, куда данная точка переместилась на втором изображении. Можно использовать *track_error* для отбора точек, у которых локальные изменения патчей слишком велики. 

Следующий аргумент *criteria* используется для установления критерия окончания вычислений. Данная структура используется во многих алгоритмах OpenCV, использующие итерационное решение:

```cpp
cvTermCriteria(
     int    type        // CV_TERMCRIT_ITER, CV_TERMCRIT_EPS или оба
    ,int    max_iter
    ,double epsilon
);
```

Как правило, данной функции вполне достаточно, чтобы сгенерировать необходимое условие. Первый аргумент данной функции *CV_TERMCRIT_ITER* или *CV_TERMCRIT_EPS* сообщает алгоритму момент прекращения - либо после некоторого количества итераций, либо когда метрика сходимости достигнет некоторого малого значения, соответственно. Следующие два вспомогательных параметра функции задают непосредственно сами критерии останова. Использование *CV_TERMCRIT_ITER | CV_TERMCRIT_EPS* позволяет задействовать оба критерия останова (что, чаще всего и используется в реальном коде).

Последний аргумент *flags* позволяет контролировать внутреннюю организацию функции; он может быть установлен в любой из или во все (при помощи побитового OR) нижеперечисленные варианты:

*CV_LKFLOW_PYR_A_READY*

Пирамида изображения первого кадра, вычисляемая перед вызовом и сохраняемая в pyrA

*CV_LKFLOW_PYR_B_READY*

Пирамида изображения второго кадра, вычисляемая перед вызовом и сохраняемая в pyrB

*CV_LKFLOW_INITIAL_GUESSES*

Массив B уже содержит исходные предположительные координаты особенностей во время вызова функции

Этот флаг полезен при работе с последовательным видео. Пирамиды изображения несколько дороговаты на вычисления, поэтому следует избегать повторных вычислений, когда это возможно. Конечный кадр составляет пару исходному кадру и вычисляется следующим за исходным кадром. Если выделение памяти под буферы производится самим пользователем (в альтернативе, функция может выполнить данное действие сама), то пирамиды для каждого изображения будут располагаться именно в этих буферах после выполнения функции. Если вызвать данную функцию с уже вычисленными значениями буферов, то перерасчет производиться не будет. Имея вычисленные передвижения точек в предыдущем кадре, можно рассчитывать на хорошую возможность задания правильных начальных локаций данных точек в следующем кадре.

В результате основной план довольно таки прост: необходимо предоставить изображения со списком точек, которые подлежат слежению *featuresA*, и вызвать функцию. После выполнения функции, необходимо проверить состояние массива для определения точек, которые удалось отследить, а затем проверить найденные новые локации данных точек *featuresB*. 

Все это порождает вопрос, который до текущего момента не был рассмотрен: как решить, какие особенности являются хорошими для отслеживания? Ранее, при рассмотрении функции *cvGoodFeaturesToTrack()*, которая использует метод Shi и Tomasi, данная проблема решалась вполне надежным способом. В большинстве случаев, хороших результатов можно достичь за счет комбинированного использования *cvGoodFeaturesToTrack()* и *cvCalcOpticalFlowPyrLK()*. И разумеется никто не может запретить использование собственных критериев определения движения!

И в заключение будет представлен небольшой пример (Пример 10-1) использования *cvGoodFeaturesToTrack()* и *cvCalcOpticalFlowPyrLK()*; рисунок 10-10.

Пример 10-1. Пирамидальный оптический поток Lukas-Kanade

```cpp
// Pyramid L-K optical flow example
//
#include <cv.h>
#include <cxcore.h>
#include <highgui.h>

const int MAX_CORNERS = 500;

int main(int argc, char** argv) {
    // Инициализация, загрузка двух изображений из файловой системы и
    // выделение памяти под изображения и структуры, необходимые для 
    // получения результата
    //
    IplImage* imgA = cvLoadImage( "image0.jpg", CV_LOAD_IMAGE_GRAYSCALE );
    IplImage* imgB = cvLoadImage( "image1.jpg", CV_LOAD_IMAGE_GRAYSCALE );

    CvSize  img_sz   = cvGetSize( imgA );
    int     win_size = 10;

    IplImage* imgC = cvLoadImage(
         "../Data/OpticalFlow1.jpg"
        ,CV_LOAD_IMAGE_UNCHANGED
    );

    // Для начала необходимо отобрать особенности, которые подлежат 
    // отслеживанию
    //
    IplImage* eig_image = cvCreateImage( img_sz, IPL_DEPTH_32F, 1 );
    IplImage* tmp_image = cvCreateImage( img_sz, IPL_DEPTH_32F, 1 );

    int             corner_count = MAX_CORNERS;
    CvPoint2D32f*   cornersA     = new CvPoint2D32f[ MAX_CORNERS ];

    cvGoodFeaturesToTrack(
         imgA
        ,eig_image
        ,tmp_image
        ,cornersA
        ,&corner_count
        ,0.01
        ,5.0
        ,0
        ,3
        ,0
        ,0.04
    );

    cvFindCornerSubPix(
         imgA
        ,cornersA
        ,corner_count
        ,cvSize(win_size, win_size)
        ,cvSize(-1, -1)
        ,cvTermCriteria(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, 0.03)
    );

    // Применение алгоритма Lucas Kanade
    //
    char    features_found[ MAX_CORNERS ];
    float   feature_errors[ MAX_CORNERS ];

    CvSize  pyr_sz = cvSize( imgA->width+8, imgB->height/3 );

    IplImage* pyrA = cvCreateImage( pyr_sz, IPL_DEPTH_32F, 1 );
    IplImage* pyrB = cvCreateImage( pyr_sz, IPL_DEPTH_32F, 1 );

    CvPoint2D32f* cornersB = new CvPoint2D32f[ MAX_CORNERS ];

    cvCalcOpticalFlowPyrLK(
         imgA
        ,imgB
        ,pyrA
        ,pyrB
        ,cornersA
        ,cornersB
        ,corner_count
        ,cvSize( win_size,win_size )
        ,5
        ,features_found
        ,feature_errors
        ,cvTermCriteria( CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, .3 )
        ,0
    );

    // Отрисовка полученного результата для наглядного представления
    //
    for( int i = 0; i < corner_count; i++ ) {
        if( features_found[i] == 0 || feature_errors[i] > 550 ) {
            printf("Error is %f/n", feature_errors[i]);
            continue;
        }

        printf("Got it/n");

        CvPoint p0 = cvPoint(
             cvRound( cornersA[i].x )
            ,cvRound( cornersA[i].y )
        );

        CvPoint p1 = cvPoint(
             cvRound( cornersB[i].x )
            ,cvRound( cornersB[i].y )
        );

        cvLine( imgC, p0, p1, CV_RGB(255,0,0), 2 );
    }

    cvNamedWindow("ImageA", 0);
    cvNamedWindow("ImageB", 0);
    cvNamedWindow("LKpyr_OpticalFlow", 0);

    cvShowImage("ImageA", imgA);
    cvShowImage("ImageB", imgB);
    cvShowImage("LKpyr_OpticalFlow", imgC);

    cvWaitKey(0);

    return 0;
}
```

![Рисунок 10-10 не найден](Images/Pic_10_10.jpg)

Рисунок 10-10. Разряженный пирамидальный оптический поток Lucas-Kanade: центральное изображение - это один из кадров видео, следуемый за изображением слева; на изображении справа проиллюстрированы вычисленные движения - "хорошие особенности для отслеживания" (внизу, справа показан поток векторов на темном фоне для повышения смотрибельности)


### Методы плотного слежения

OpenCV содержит ещё два метода оптического потока, которые на данный момент используются крайне редко. Эти функции, как правило, гораздо медленнее Lukas-Kanade; кроме того, они не поддерживают сопоставление в пределах масштабирования пирамиды изображения и потому не могут отслеживать большие перемещения. По этим причинам в данном разделе данные методы будут рассмотрены кратко.

**Метод Horn-Schunck**

Метод Horn и Schunck был разработан в 1981 году. Это был один из первых методов, который использовал предположение о постоянстве яркости и на основе которого были выведены основные уравнения постоянства яркости. Решение этих уравнений, разработанное Horn и Schunck, основывалось на гипотезе о сглаживании ограничения скоростей ![Формула 10-16 не найдена](Images/Frml_10_16.jpg) и ![Формула 10-17 не найдена](Images/Frml_10_17.jpg). Это ограничение было получено путем минимизации скорости упорядоченного Лапласиана оптического потока:

![Формула 10-18 не найдена](Images/Frml_10_18.jpg)

где α постоянный весовой коэффициент, более известный как *постоянная регуляризации*. Значение α влияет на сглаженность оптического потока (чем больше значение, тем выше сглаженность). Это относительно простое ограничение принудительного сглаживания и имеет эффект "наказания области", в которой поток изменяется по величине. Как и в Lucas-Kanade, метод Horn-Schunck полагается на итерационное решение дифференциальных уравнений. 

```cpp
void cvCalcOpticalFlowHS(
     const CvArr*   imgA
    ,const CvArr*   imgB
    ,int            usePrevious
    ,CvArr*         velx
    ,CvArr*         vely
    ,double         lambda
    ,CvTermCriteria criteria
);
```

где *imgA* и *imgB* должны быть 8-битными, одноканальными изображениями. Скорости по x и по y будут сохранены в параметры *velx* и *vely*, соответственно, и должны быть 32-битными, вещественными, одноканальными изображениями. Параметр *usePrevious* сообщает алгоритму об необходимости использования скоростей *velx* и *vely*, вычисленных на предыдущем кадре, в качестве отправной точки для вычисления новых скоростей. Параметр *lambda* это вес, связанный с *множителем Лагранжа*. Скорее всего в этом метсе может возникнуть вопрос: "Что такое множитель Лагранжа?" Множитель Лагранжа появляется при попытке минимизации (одновременной) обоих уравнений: уравнения перемещения яркости и уравнений сглаживания; множитель - это относительный вес ошибок минимизации.

**Метод блочного сопоставления**

Скорее всего у любознательного читателя, дочитавшего до данного раздела, может возникнуть вопрос: "Почему столь большое внимание привлекает к себе оптический поток? Можно ведь просто сопоставить пиксели из одного кадра с пикселями другого кадра". Термин "блочное сопоставление" является обобщенным для целого класса подобных алгоритмов, в которых изображение разделяется на небольшие области, именуемые *блоками*. Блоки, как правило, имеют форму квадрата и содержат определенное количество пикселей. На практике довольно часто данные блоки могут пересекаться. Алгоритмы блочного сопоставления разделяют текущее и предыдущее изображения на блоки с последующим вычислением перемещения этих блоков. Алгоритмы подобного рода играют важную роль во многих алгоритмах сжатия видео, а также в оптических потоках компьютерного зрения.

Т.к. алгоритм блочного сопоставления оперирует скоплениями пикселей, а не отдельными пикселями, то возвращаемые "изображения скорости", как правило, более низкого разрешения, чем исходные изображения. Но это не всегда так; все зависит от степени пересечения между блоками. Размер изображения, получаемого после выполнения алгоритма, задается следующей формулой:

![Формула 10-19 не найдена](Images/Frml_10_19.jpg)

Реализация данного метода в OpenCV использует поиск по спирали, который выстраивает свою работу на основе локации исходного блока (в предыдущем кадре) и последующим сравнением кандидатов в новые блоки с исходным. Это сравнение является абсолютной суммой разницы между пикселями (т.е. расстоянием L1). Если найдено достаточно хорошее совпадение, то поиск прекращается. Функция, реализующая данный метод, имеет следующий вид:

```cpp
void cvCalcOpticalFlowBM(
     const CvArr*   prev
    ,const CvArr*   curr
    ,CvSize         block_size
    ,CvSize         shift_size
    ,CvSize         max_range
    ,int            use_previous
    ,CvArr*         velx
    ,CvArr*         vely
);
```

Параметры *prev* и *curr* это предыдущее и текущее изображения; оба должны быть 8-битными, одноканальными изображениями. *block_size* это размер блока, а *shift_size* размер шага между блоками (этот параметр контролирует - если это происходит - степень пересечения блоков). Параметр *max_range* это размер области вокруг блока, в которой будет производиться поиск соответствующего блока в следующем кадре. Если задан параметр *use_previous*, то *velx* и *vely* указывают на отправную точку, с которой начинается поиск блоков. (Если *use_previous == 0*, поиск блока будет производиться по области на расстоянии *max_range* от локации исходного блока. Если *use_previous != 0*, то центр поиска будет соответствовать первым смещениям ![Формула 10-22 не найдена](Images/Frml_10_22.jpg) и ![Формула 10-23 не найдена](Images/Frml_10_23.jpg)). Параметры *velx* и *vely* являются 32-битными одноканальными изображениями, которые хранят рассчитанные движения блоков. Как уже было сказано ранее, вычисления производятся на уровне блоков, поэтому вычисленные координаты будут соответствовать блокам, а не отдельным пикселям исходного изображения.

