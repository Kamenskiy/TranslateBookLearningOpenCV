## [П]|[РС]|(РП) Более сложные манипуляции

Всё, что было рассмотрено до сих пор, было достаточно простым. Каждая из функций несла очевидную необходимость. В совокупности, они образуют хорошую основу для всего того, что можно сделать с гистограммами в контексте компьютерного зрения (или же в каких-либо других контекстах). В данном разделе речь пойдет о более сложных процедурах, которые имеются в OpenCV и которые чрезвычайно полезны в некоторых приложениях. Эти процедуры включают в себя более сложные методы сравнения двух гистограмм, а так же инструменты для вычисления и/или визуализации частей изображения, которые соответствуют заданной части гистограммы. 


### Earth Mover’s Distance

Изменение освещения может привести к сдвигу цветовых значений (рисунок 7-5), хотя такой сдвиг, как правило, не изменяет форму гистограммы значений цвета, но при изменении положения цветовых значений, схемы сравнения гистограмм обречены на провал. Однако если вместо гистограмм *сравнения* использовать гистограммы *расстояния*, то можно сравнить две гистограммы, несмотря на сдвиг одной гистограммы относительно другой на малые расстояния. Earth mover’s distance (EMD) является метрикой; по сути это мера работы необходимая для преобразования одной или нескольких гистограмм в новое положение. Она работает с любым количеством измерений.

Если снова взглянуть на рисунок 7-4, то можно увидеть характер изменения расстояния EMD. Точное совпадение соответствует расстоянию равное 0. Совпадение на половину это половина "полного перебора" - то количество, которое потребуется, чтобы перенести половину левой гистограммы в соседний слот. И наконец, для перемещения всей гистограммы на один шаг вправо потребуется вся единица расстояния (например, для изменения гистограммы в "совершенно несовпадающую" гистограмму).

Алгоритм EMD имеет весьма общий характер; это позволяет пользователям устанавливать собственную дистанционную метрику или собственную матрицу стоимости перемещения. Можно зафиксировать, где гистограмма "material" изменяется при переходе от одной гистограммы к другой или можно воспользоваться нелинейными показателями расстояния, полученные из предварительной информации о данных. В OpenCV EMD соответствует функция *cvCalcEMD2()*:

```cpp
float cvCalcEMD2(
     const CvArr*       signature1
    ,const CvArr*       signature2
    ,int                distance_type
    ,CvDistanceFunction distance_func   = NULL
    ,const CvArr*       cost_matrix     = NULL
    ,CvArr*             flow            = NULL
    ,float*             lower_bound     = NULL
    ,void*              userdata        = NULL
);
```

Функция *cvCalcEMD2()* имеет достаточно много аргументов. Можно подумать, что это решение довольно таки сложное для такой интуитивной функции, но сложность проистекает от возможности тонкой настройки алгоритма (если есть необходимость в знании всех "кровавых" подробностей, то необходимо изучить статью S. Peleg, M. Werman и H. Rom 1989 года "A Unified Approach to the Change of Resolution: Space and Gray-Level", а затем заглянуть в руководство OpenCV и изучить файл *...\opencv\docs\ref\opencvref_cv.htm*). К счастью, функция может быть использована в более обобщенной и интуитивно понятной форме без большинства аргументов (на это указывает *= NULL* в определении функции). В примере 7-2 показана упрощённая версия этой функции.

Пример 7-2. Упрощённая версия функции *cvCalcEMD2()*

```cpp
float cvCalcEMD2(
     const CvArr*   signature1
    ,const CvArr*   signature2
    ,int            distance_type
);
```

Параметр *distance_type* для упрощённой версии *cvCalcEMD2()* может быть либо *расстоянием Manhattan* (*CV_DIST_L1*), либо *расстоянием Euclidean* (*CV_DIST_L2*). Хотя EMD и используется для гистограмм, интерфейс упрощенной версии функции предполагает использование массивов для первых двух аргументов. 

Эти массивы всегда типа *float* и состоят из строк, содержащие количество контейнеров гистограммы и их координаты. Для одномерной гистограммы (рисунок 7-4) сигнатуры (перечислимые строки массива) левой колонки гистограммы (пропускная модель) будет выглядеть следующим образом: верхняя [1, 0; 0, 1]; средняя [0.5, 0; 0.5, 1]; нижняя [0, 0; 1, 1]. Если взять контейнер трехмерной гистограммы с 537 контейнерами (x, y, z), то сигнатура строки с индексом (7, 43, 11) будет [537, 7; 43, 11]. Это необходимый шаг преобразования гистограмм в сигнатуры.

В качестве примера, предположим, что имеется две гистограммы *hist1* и *hist2*, которые необходимо преобразовать в сигнатуры *sig1* и *sig2*. Для усложнения задачи, будут использованы двумерные гистограммы размерностью *h_bins × s_bins*. Пример 7-3 отображает процесс преобразования этих двух гистограмм в две сигнатуры. 

Пример 7-3. Создание сигнатур гистограмм для EMD сравнения

```cpp
// Преобразование гистограмм в сигнатуры для EMD сравнения
// На входе имеются двумерные гистограммы hist1 и hist2
// обе имеют размерности h_bins × s_bins (хотя для EMD,
// гистограммы не должны совпадать по размеру)
//
CvMat* sig1,sig2;
int numrows = h_bins*s_bins;

// Создание матриц для хранения сигнатур
//
sig1 = cvCreateMat(numrows, 3, CV_32FC1); // 1 count + 2 coords = 3
sig2 = cvCreateMat(numrows, 3, CV_32FC1); // sig1 и sig2 имеют тип float

// Заполнение сигнатур для двух гистограмм
//
for( int h = 0; h < h_bins; h++ ) {
    for( int s = 0; s < s_bins; s++ ) {
        float bin_val = cvQueryHistValue_2D( hist1, h, s );
        cvSet2D(sig1,h*s_bins + s,0,cvScalar(bin_val)); // значение контейнера
        cvSet2D(sig1,h*s_bins + s,1,cvScalar(h));       // Coord 1
        cvSet2D(sig1,h*s_bins + s,2,cvScalar(s));       // Coord 2

        bin_val = cvQueryHistValue_2D( hist2, h, s );
        cvSet2D(sig2,h*s_bins + s,0,cvScalar(bin_val)); // значение контейнера
        cvSet2D(sig2,h*s_bins + s,1,cvScalar(h));       // Coord 1
        cvSet2D(sig2,h*s_bins + s,2,cvScalar(s));       // Coord 2
    }
}
```

В этом примере функция *cvSet2D()* (использование *cvSetReal2D()* или *cvmSet()* было бы более компактным и эффективным решением, но пример проясняет выбранный вариант: дополнительные накладные расходы малы по сравнению с фактическими расчетами расстояния в EMD) принимает *CvScalar()*, чтобы задать значения массива, хотя каждая запись в данной матрице имеет тип *float*. Для удобства используется встроенный макрос *CvScalar()*. После получения сигнатур можно вычислять меру расстояния. В примере 7-4 показано вычисление расстояния *Euclidean*.

Пример 7-4. Использование EMD для измерения сходства между распределениями

```cpp
float emd = cvCalcEMD2( sig1, sig2, CV_DIST_L2 );
printf( "%f", emd );
```


### Обратная проекция

Обратная проекция это способ записи пикселей (*cvCalcBackProject()*) или участка пикселей (*cvCalcBackProjectPatch()*), соответствующие распределению пикселей в модели гистограммы. Например, имея гистограмму телесного цвета можно воспользоваться обратной проекцией, чтобы найти цвета на изображении, соответствующие цвету кожи. В OpenCV функция для выполнения подобного рода поиска выглядит следующим образом:

```cpp
void cvCalcBackProject(
     IplImage**         image
    ,CvArr*             back_project
    ,const CvHistogram* hist
);
```

Ранее уже было рассказано о массиве одноканальных изображений *IplImage*\*\* при разборе функции *cvCalcHist()* (раздел "Базовые манипуляции над гистограммами"). Число изображений в этом массиве точно такое же - и в том же порядке - что использовалось при построении модели гистограммы *hist*. В примере 7-1 показано, как преобразовать изображение в одноканальные кадры и сделать из них массив. Изображение или массив *back_project* это одноканальное 8-битное или вещественное изображение того же размера, что и входное изображение. Значения *back_project* устанавливаются в значения контейнеров *hist*. Если гистограмма нормализована, тогда эти значения могут быть связаны с условной вероятностью значения (т.е. вероятность того, что пиксели в изображении - члены типа, характеризуемые гистограммой *hist*). На рисунке 7-6 используется гистограмма телесных цветов для получения изображения вероятностей телесных цветов.

![Рисунок 7-6 не найден](Images/Pic_7_6.jpg)

Рисунок 7-6. Обратная проекция гистограммы оценивает каждый пиксель, основываясь на значение его цвета: гистограмма телесного цвета HSV (сверху слева) используется для преобразования изображения руки (сверху справа) в изображение вероятностей телесных цветов (внизу справа); нижнее левое изображение - это гистограмма изображения руки

В частности, в случае гистограммы H-S, если C это цвет пикселя и F это вероятность того, что пиксель соответствует телесному цвету, тогда имеем вероятность p(C|F) того, что цвет пикселя действительно соответствует телесному цвету. Но это не значит, что p(F|C) - это вероятность того, что телесный цвет соответствует цвету пикселя. Тем не менее, эти две вероятности связаны теоремой Байеса и если в целом известна вероятность встречи объекта телесного цвета на сцене, а так же общая вероятность попадания в диапазон телесного цвета, тогда можно вычислить p(F|C) от p(C|F). В частности, теорема Байеса устанавливает следующее соответствие: 

![Формула 7-6 не найдена](Images/Frml_7_6.jpg)

Когда *back_project* - это изображение типа byte, а не float, то либо над гистограммой не нужно выполнять нормализацию, либо это изображение необходимо масштабировать перед использованием. Причина этого в том, что максимально возможное значение нормализованной гистограммы 1, так что, все, что меньше будет округлено до 0 в 8-битном изображении. Так же, возможно, потребуется масштабировать *back_project* для того, чтобы можно было увидеть собственными глазами разницу в высоте контейнеров гистограммы. 

**Обратная проекция, основанная на patch**

Базовый метод обратной проекции может быть использован для моделирования - является ли пиксель членом определенного типа объекта (когда данный тип объекта был смоделирован гистограммой). Это не совсем так же, как вычисление вероятности наличия конкретного объекта. Альтернативный метод предполагает рассмотрение субрегиона изображения и признака (например, цвета) гистограммы в этом субрегионе и проверку на соответствие гистограммы субрегиона гистограмме модели; потом можно связать с каждым субрегионом вероятность того, что моделируемый объект присутствует в данном субрегионе. 

Таким образом, так же, как *cvCalcBackProject()* позволяет нам вычислять является ли пиксель частью заданного объекта, *cvCalcBackProjectPatch()* позволяет узнавать, является ли *patch* частью заданного объекта. Как показано на рисунке 7-7, функция *cvCalcBackProjectPatch()* использует окно выборки по всему исходному изображению. В каждом месте исходного массива изображения, все пиксели *patch* используются для установки одного пикселя в конечном изображении. Это важно, поскольку многие свойства изображения, например, такое как текстура, не могут быть определены на уровне отдельных пикселей, только на уровне группы пикселей.

![Рисунок 7-7 не найден](Images/Pic_7_7.jpg)

Рисунок 7-7. Обратная проекция: скользящее окно по поверхности исходного изображения используется для установки соответствующего пикселя в конечном изображении; для нормализованной гистограммы изображение может быть интерпретировано как карта вероятности с указанием вероятного места присутствия объекта

Для упрощения описанных примеров, цвет был подобран для создаваемой модели гистограммы. Таким образом, на рисунке 7-6 вся рука "светится", потому что пиксели соответствуют модели гистограммы телесного цвета. Использование *patch* помогает при обнаружении статистических свойств, которые появляются в локальных областях при изменении локальной интенсивности, при этом текстура формируется до конфигурирования свойств, формирующие весь объект. Существует два варианта использования *cvCalcBackProjectPatch()*: в качестве обнаружения региона, когда окно выборки меньше объекта и в качестве детектора объекта, когда окно выборки соизмеримо с объектом. Рисунок 7-8 отображает использование *cvCalcBackProjectPatch()* для поиска региона. Все начинается с модели гистограммы телесных цветов и передвижения небольшого окна вдоль изображения так, что в каждый пиксель обратной проекции записывается вероятность того, что текущий пиксель соответствует телесному цвету при учете всех окружающих окно пикселей в оригинальном изображении. На рисунке 7-8 рука намного больше сканирующего окна, что является преимуществом при распознавании региона ладони. На рисунке 7-9 показана гистограмма, соответствующая распознанной синей кружке. В отличие от рисунка 7-8, где был обнаружен регион, рисунок 7-9 показывает как *cvCalcBackProjectPatch()* может быть использован для обнаружения объекта. Когда размеры окна примерно такого же размера, как объект, который требуется найти на изображении, то искомый объект "светится" на изображении обратной проекции. Поиск пиковых значений на изображении обратной проекции соответствует поиску местоположения объекта (на рисунке 7-9 это кружка).

```cpp
void cvCalcBackProjectPatch(
     IplImage**     images
    ,CvArr*         dst
    ,CvSize         patch_size
    ,CvHistogram*   hist
    ,int            method
    ,float          factor
);
```

![Рисунок 7-8 не найден](Images/Pic_7_8.jpg)

Рисунок 7-8. Обратная проекция используемая для построения гистограммы объекта телесного цвета, где окно (маленький белый квадрат в верхней правой части окна) намного меньше руки; гистограмма соответствует распределению телесных цветов с пиковыми значениями преимущественно в центре руки

![Рисунок 7-9 не найден](Images/Pic_7_9.jpg)

Рисунок 7-9. Использование cvCalcBackProjectPatch () для поиска объекта (чашки кофе), размер которого примерно соответствует размеру *patch* (белый квадрат в верхнем правом изображении): гистограмма оттенок-насыщенность для искомого объекта (левый верхний угол), которая может быть сопоставлена с HS гистограммой для изображения в целом (нижний левый угол); результат (нижний правый угол) показывает, что объект удалось довольно таки легко определить в силу своего цвета

Аргумент *images* - это тот же массив одноканального изображения, который был использован в *cvCalcHist()* при создании гистограммы. Тем не менее, конечное изображении *dst* отличается: оно может быть только одноканальным вещественным изображением размера *( images[0][0].width – patch_size.x + 1, images[0][0].height – patch_size.y + 1 )*. Указанный размер объясняется тем, что центральный пиксель в *patch* используется для указания места для результата в конечном изображении *dst*, поэтому теряется половина размера *patch* по краям изображения со всех сторон. Параметр *patch_size* задает размер *patch* и может быть установлен с помощью удобного макроса *cvSize(width, height)*. Параметр гистограмма *hist* был уже рассмотрен ранее. Параметр метода сравнения *method* принимает все те же значения, что и в случае с *cvCompareHist()* (раздел "Сравнение двух гистограмм") (Необходимо соблюдать осторожность при выборе метода, потому что некоторые отображают наилучший результат как 1, а некоторые как 0). Последний аргумент *factor* задает уровень нормализации; этот параметр так же был описан при рассмотрении *cvNormalizeHist()*. По умолчанию он соответствует 1, любое более высокое значение помогает при визуализации. Благодаря этому параметру существует возможность нормализовать *hist* перед использованием *cvCalcBackProjectPatch()*.

И в заключении остался один не решенный вопрос: после того, как найдено изображение вероятности объекта, как этим изображением можно воспользоваться, что бы найти искомый объект? Для поиска можно воспользоваться функцией *cvMinMaxLoc()*, о которой шла речь в главе 3. Максимальные значения (если при этом еще и сгладить изображение), скорее всего, укажут на искомый объект.


### Шаблон соответствия

Шаблон соответствия, используемый в *cvMatchTemplate()*, основан не на гистограммах; функция сравнивает текущее изображение *patch* с исходным изображением при помощи "скольжения" *patch* над исходным изображением, при использовании одного из методов сравнения, описанных в конце данного раздела.

Если, как показано на рисунке 7-10, имеется *patch*, содержащий изображение лица, то можно "скользить" этим изображением лица по исходному изображению для поиска совпадений, которые указывали бы, что на исходном изображении присутствует лицо. Вызов функции аналогичен вызову *cvCalcBackProjectPatch()*:

![Рисунок 7-10 не найден](Images/Pic_7_10.jpg)

Рисунок 7-10. Использование cvMatchTemplate() для поиска лица при помощи шаблона

```cpp
void cvMatchTemplate(
     const CvArr*   image
    ,const CvArr*   templ
    ,CvArr*         result
    ,int            method
);
```

В отличие от *cvCalcBackProjectPatch()*, на вход подается поток данных в виде 8-битного или вещественного типа или цветное изображение. Шаблон для сравнения *templ* это просто *patch* от исходного изображения, содержащее искомый объект поиска. Конечное изображение объекта будет размещено в *result*; это одноканальное типа *byte* или *float* изображение размера *( images->width – patch_size.x + 1, rimages->height – patch_size.y + 1 )*, аналогичное ранее рассмотренному в функции *cvCalcBackProjectPatch()*. Методы сравнения шаблонов *method* несколько сложнее, что будет показано далее. Обозначения: *I* - исходное изображение, *T* - шаблон, *R* - результат.

**Метод сравнения - квадрат разности (method = CV_TM_SQDIFF)**

Для данного метода идеальное соответствие равно 0, а плохое более высокому значению:

![Формула 7-7 не найдена](Images/Frml_7_7.jpg)

**Метод сравнения - корреляция (method = CV_TM_CCORR)**

Это метод мультипликативного соответствия шаблона изображению, при этом плохое соответствие близко или равно 0, а идеальное равно довольно таки большому значению:

![Формула 7-8 не найдена](Images/Frml_7_8.jpg)

**Метод сравнения - коэффициент корреляции (method = CV_TM_CCOEFF)**

Идея метода состоит в сравнении шаблона относительно его среднего и изображения относительно его среднего; так идеальное соответствие равно 1, худшее -1, а значение 0 означает, что корреляции нет (случайное выравнивание).

![Формула 7-9 не найдена](Images/Frml_7_9.jpg)

![Формула 7-10 не найдена](Images/Frml_7_10.jpg)

![Формула 7-11 не найдена](Images/Frml_7_11.jpg)

**Метод нормализации**

Для каждого из трех ранее описанных методов есть нормализованная версия, впервые разработанная Galton и описанная Rodgers. Как уже было сказано ранее нормализованный метод может помочь уменьшить влияние освещения на различия между шаблоном и изображением. В каждом из трех случаев коэффициент нормализации один и тот же:

![Формула 7-12 не найдена](Images/Frml_7_12.jpg)

Значения для *method*, которые дают нормализованный расчет, приведены в таблице 7-2.

Таблица 7-2. Значения параметра method для нормализации шаблона сравнения

| Значение параметра | Формула расчета |
| -- | -- |
| CV_TM_SQDIFF_NORMED | ![Формула 7-13 не найдена](Images/Frml_7_13.jpg) |
| CV_TM_CCORR_NORMED | ![Формула 7-14 не найдена](Images/Frml_7_14.jpg) |
| CV_TM_CCOEFF_NORMED | ![Формула 7-15 не найдена](Images/Frml_7_15.jpg) |

Как обычно, более точные соответствия получаются (за счет большего числа вычислений) при переходе от простых методов (квадрат разности) к более сложным (коэффициент корреляции). Для выбора наилучшего в той или иной ситуации необходимо проводить небольшое тестирование каждого и сравнивать их в соотношении точность - скорость. 

Опять же, необходимо соблюдать осторожность при интерпретации результатов. Метод квадрат разности дает лучший результат с минимальным количествои точек, в то время как методы корреляция и коэффициент корреляции дают лучшие результаты с максимальным количеством точек. 

Как и в случае с *cvCalcBackProjectPatch()* при использовании *cvMatchTemplate()* чтобы получить необходимое изображение *result* можно воспользоваться *cvMinMaxLoc()* для поиска точки наилучшего соответствия. Опять же, необходимо гарантировать хорошую площадь совпадений вокруг этой точки во избежания случайного выравнивания шаблона, что порою случается для хорошего выполнения работы. Хорошее совпадение должно иметь хорошие совпадения рядом, потому что незначительные смещения шаблона не должны сильно изменять результаты реальных совпадений. В поисках лучшего соответствия может быть сделано незначительное сглаживание изображения *result* перед поиском максимума (для корреляции и коэффициента корреляции) или минимума (для квадрата разности). Морфологические операции так же могут быть полезны при решении данной задачи.

Пример 7-5 дает хорошее представление того, как ведут себя различные методы шаблона соответствия. Эта программа в начале считывает сопоставляемые шаблон и изображение, а затем выполняет сравнение при помощи ранее рассмотренных методов.

Пример 7-5. Шаблон сопоставления

```cpp
#include <cv.h>
#include <cxcore.h>
#include <highgui.h>
#include <stdio.h>

int main( int argc, char** argv) {
    IplImage *src, *templ, *ftmp[6]; // в ftmp будет помещен результат
    int i;

    if( argc == 3) {
        // Загрузка исходного изображения (где искать)
        // 
        if((src=cvLoadImage(argv[1], 1))== 0) {
            printf("Error on reading src image %s\n", argv[i]);
            return(-1);
        }

        // Загрузка шаблона (что искать)
        // 
        if((templ=cvLoadImage(argv[2], 1))== 0) {
            printf("Error on reading template %s\n", argv[2]);
            return(-1); 
        }

        // Создание конечного изображения
        // 
        int iwidth = src->width - templ->width + 1;
        int iheight = src->height - templ->height + 1;

        for(i=0; i < 6; ++i) {
            ftmp[i] = cvCreateImage(cvSize(iwidth, iheight), 32, 1);
        }

        // Сравнение шаблона с изображением
        // 
        for(i=0; i<6; ++i) {
            cvMatchTemplate( src, templ, ftmp[i], i);
            cvNormalize(ftmp[i], ftmp[i], 1, 0, CV_MINMAX);
        }

        // Отображение результатов
        // 
        cvNamedWindow("Template", 0);
        cvShowImage("Template", templ);
        cvNamedWindow("Image", 0);
        cvShowImage("Image", src);
        cvNamedWindow("SQDIFF", 0);
        cvShowImage("SQDIFF", ftmp[0]);
        cvNamedWindow("SQDIFF_NORMED", 0);
        cvShowImage("SQDIFF_NORMED", ftmp[1]);
        cvNamedWindow("CCORR", 0);
        cvShowImage("CCORR", ftmp[2]);
        cvNamedWindow("CCORR_NORMED", 0);
        cvShowImage("CCORR_NORMED", ftmp[3]);
        cvNamedWindow("CCOEFF", 0);
        cvShowImage("CCOEFF", ftmp[4]);
        cvNamedWindow("CCOEFF_NORMED", 0);
        cvShowImage("CCOEFF_NORMED", ftmp[5]);

        // Позволить пользователю увидеть результаты
        // 
        cvWaitKey(0);
	}
    else { 
        printf("Call should be: matchTemplate image template \n");
    }
}
```

В данном примере стоит обратить внимание на функцию *cvNormalize()*, которая позволяет отображать результаты на постоянной основе (некоторые из этих методов могут возвращать отрицательные значения). При нормализации используется флаг *CV_MINMAX*; это велит функции смещать и масштабировать току на изображении так, что все возвращаемые значения будут принимать значения из диапазона от 0 до 1. Рисунок 7-11 отображает результаты перемещения шаблона лица поверх исходного изображения (рисунок 7-10) при использовании все возможных методов функции *cvMatchTemplate()*. Для наружного формирования изображения, почти всегда лучше использовать один из нормализованных методов. Среди все возможных методов, коэффициент корреляции дает наиболее четкое очертание соответствия - но, как и ожидалось, обладает большой вычислительной стоимостью. Для конкретного приложения, таких, как автоматическая проверка частей или отслеживание признаков в видео, необходимо перебирать все метода, что бы найти баланс между скоростью и точностью. 

![Рисунок 7-11 не найден](Images/Pic_7_11.jpg)

Рисунок 7-11. Результаты применения шести методов поиска по шаблону к рисунку 7-10: лучшее совпадение для метода квадрат разности равен 0, а для других методов это точка максимума; таким образом, совпадения в левой колонке соответствует темным областям, а для двух других колонок светлым

